Applies to optimization problems.

transform exponential-time algorithms into polynomial-time algorithms.

Divde-and-conquer, disjoint subproblems
Dynamic programming, subproblems overlap when subproblems share subproblems.

----> apply it to optimization problems!!!!!

4 steps:
1. Characterize the structure of an optimal solution.
2. Recursively define the value of an optimal solution.
3. Compute the value of an optimal solution, typically in a bottom-up fashion.
4. Construct an optimal solution from computed information.


Rod cutting problem:
We can cut up a rod of length n in 2^(n-1) different ways, since we have an independent option of cutting, or not cutting.

r(n) = pn + (r(1)+r(n-1) + (r(2)+r(n-2)) +...+ (r(n-1)+r(1))
simplify: r(n) = max(pi+(r(n-i) 

recursive top-down implementation:
max(a, p[i]+cut-rod(p,n-i)
it returns the maximum revenue possible for a rod of length n.

This algorithm is so inefficient. The problem is that CUT_ROD calls itself recursively over and over again with the same parameter values;
it solves the same subproblems repeatedly.

Convert it into an efficient algorithm. ---> dynamic programmming.
Dynamic programming thus uses additional memory to save computation time; it serves an example of a time-memory trade-off.

It's bottom-up method!!!!
Time complexity is O(n^2) due to it's double loop.





